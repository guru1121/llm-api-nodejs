# ğŸš€ Gemini LLM API Integration (Node.js + Express)

A simple REST API built with **Node.js** and **Express** that integrates with **Google Gemini LLM (`gemini-2.5-flash`)** to generate AI-powered responses.

---

## ğŸ“Œ Features

- REST API endpoint for chat interaction  
- Integration with Gemini 2.5 Flash model  
- Environment variable support using `dotenv`  
- Error handling for API failures  
- Lightweight and easy to extend  

---

## ğŸ›  Tech Stack

- Node.js  
- Express.js  
- Google Gemini 2.5 Flash (Generative Language API)  
- dotenv  
- express-rate-limit  

---

## ğŸ“‚ Project Structure

.
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ app.js
â”‚ â”œâ”€â”€ server.js
â”‚ â”œâ”€â”€ routes/
â”‚ â”‚ â””â”€â”€ chat.routes.js
â”‚ â”œâ”€â”€ services/
â”‚ â”‚ â””â”€â”€ gemini.service.js
â”‚ â””â”€â”€ middleware/
â”‚ â””â”€â”€ rateLimiter.js
â”‚
â”œâ”€â”€ .env
â”œâ”€â”€ package.json
â””â”€â”€ README.md


---

## âš™ï¸ Installation

### 1ï¸âƒ£ Clone Repository

```bash
git clone https://github.com/guru1121/llm-api-nodejs
cd your-repo-name
2ï¸âƒ£ Install Dependencies
npm install
3ï¸âƒ£ Setup Environment Variables
Create a .env file in the root directory:

GOOGLE_API_KEY=gemini_api_key_here
PORT=3000
âš ï¸ Never commit your .env file.

Add this to .gitignore:

node_modules
.env
â–¶ï¸ Run the Server
npm start
Or if using nodemon:

npm run dev
Server will start at:

http://localhost:3000
ğŸ“¡ API Endpoints
ğŸ”¹ Health Check
GET /health
Response:

{
  "status": "OK"
}
ğŸ”¹ Chat Endpoint
POST /chat
Request Body:

{
  "chat": "Explain JWT in simple terms"
}
Response:

{
  "response": "JWT stands for JSON Web Token..."
}

ğŸ” Authentication
The Gemini API key is securely sent using request headers:

x-goog-api-key: YOUR_API_KEY
The API key is never exposed in the URL.

ğŸ“Š Model Used
gemini-2.5-flash

Free Tier Limits
5 requests per minute

20 requests per day

Rate limiting middleware is implemented to prevent quota exhaustion.

â— Error Handling
Returns 400 for invalid or missing input

Returns actual Gemini API status codes (e.g., 429)

Handles server errors gracefully

ğŸ”’ Security Best Practices
API key stored in .env

.env excluded from version control

Rate limiting applied to /chat

Input validation implemented

ğŸš€ Future Improvements
Add Swagger API documentation

Implement chat memory

Add streaming responses

Add JWT authentication

Dockerize application

Deploy to AWS / Render / Railway

ğŸ‘¨â€ğŸ’» Author
Gurunand Mourya
Software Developer